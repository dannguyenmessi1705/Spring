# Observability và Monitoring trong Microservices
## 1. Giới thiệu
### 1.1. Observability
`Observability` là khả năng hiểu trạng thái bên trong của hệ thống dựa trên các dữ liệu đầu ra.

Trong `Microservices`, observability có được bởi việc thu thấp, phân tích dữ liệu từ nhiều nguồn khác nhau như logs, metrics, traces.
- `Metrics`: Đơn vị đo lường sức khỏe của hệ thống. Chúng được sư dụng để theo dõi các số liệu như: `mức độ sử dụng CPU`, `lưu lượng mạng`, `số lượng request`, `thời gian xử lý request`,...
- `Logs`: Sẽ ghi lại các sự kiện xảy ra trong hệ thống. Chúng được sử dụng để theo dõi các sự kiện như: `lỗi`, `thông báo`, `cảnh báo`, `exception`, `các sự kiện không lường trước`,...
- `Traces`: Ghi lại các đường dẫn mà 1 request đi qua trong hệ thống. Chúng được sử dụng để theo dõi hiệu năng của 1 request và xác định các vấn đề nếu có.

### 1.2. Monitoring
`Monitoring` trong `Microservices` tham gia vào việc kiểm tra các dữ liệu có sẵn từ `Observability` và tạo ra các cảnh báo cho các trạng thái thất bại hoặc không bình thường.

Quá trình này thu thập và phân tích dữ liệu từ hệ thống để xác định và troubleshoot các vấn đề.

`Monitoring` rất quan trọng trong `Microservices` vì nó cho phép:
- `Identify and troubleshoot problems`: Bằng việc thu thập và phân tích dữ liệu từ hệ thống, chúng ta có thể xác định và giải quyết các vấn đề.
- `Track the health of microservices`: Chúng ta có thể theo dõi sức khỏe của các microservices và xác định các vấn đề trước khi chúng trở nên nghiêm trọng.
- `Optimize microservices`: Có thể xác định những khu vực cần cải thiện và tối ưu hóa hiệu suất của hệ thống.

### 1.3. Sự khác biệt giữa Observability và Monitoring
| Tính năng | Monitoring | Observability |
|:---------:|:----------:|:-------------:|
| Mục đích | Xác định và giải quyết vấn đề | Hiểu rõ các trạng thái bên trong hệ thống |
| Dữ liệu | Dữ liệu cụ thể (Metrics, traces, log) | Gồm nhiều dữ liệu đa dạng |
| Cách tiếp cận | Phản ứng khi có vấn đề | Proactive, chủ động phát hiện vấn đề |

## 2. Quản lý logs trong Microservices với `Grafana Loki & Promtail`
### 2.1. Giới thiệu
`Grafana Loki` là một hệ thống thu thập và lưu trữ logs cho các hệ thống phân tán. Nó được thiết kế để hoạt động với `Prometheus` và `Grafana` để cung cấp một giải pháp giám sát hoàn chỉnh cho hệ thống.


`Promtail` là một `agent` thu thập logs từ các `Microservices` sau đó `xử lý` và `chuyển tiếp` logs đến `Loki`.

`Loki` sẽ `lưu trữ` và `tổng hợp` logs từ `Promtail` và cung cấp các `truy vấn`, `tìm kiếm` logs hiệu quả đến `Grafana`.

`Grafana` sẽ `hiển thị` và `tạo biểu đồ` logs từ `Loki` để giúp người dùng dễ dàng theo dõi và phân tích logs.

### 2.2. Cài đặt với Docker Compose
Tham khảo tại: [Grafana Loki Get Started](https://grafana.com/docs/loki/latest/get-started/quick-start/)
#### 2.2.1. Luồng hoạt động cua `Grafana Loki` với các container
Đê chạy `Grafana Loki` với `Docker Compose`, chúng ta cần có các `container` sau:
1. `Microservices`: Đây là các `container` chứa các `Microservices` cần thu thập logs.
2. `Grafana Alloy`: Thu thập các dòng `logs` từ các `Microservices` và chuyển tiếp đến `Loki` thông qua các cổng `port`
3. `Gateway (NGINX)`: Nhận các request và chuyển tiếp chúng tới các `container` khác trong hệ thống `Grafana Loki`.
4. `Loki read`: Đọc, truy vấn các `logs` từ `Loki` và hiển thị chúng trên `Grafana`.
5. `Loki write`: Nhận các `logs` từ `Grafana Alloy` và lưu trữ chúng vào `Loki`.
6. `Loki backend`: Xử lý dữ liệu của `Grafana` bao gồm các components như `Index Gateway`, `Compactor`, `Ruler`, `Bloom Compactor (Experimental)`, `Bloom Gateway (Experimental)`.
7. `Minio`: Một `object storage` S3-compatible để lưu trữ dữ liệu của `Loki`.
8. `Grfana`: Hiển thị và tạo biểu đồ logs từ `Loki`.

#### 2.2.2. Tạo các file `yaml` cấu hình cho `Loki` và `Alloy`
>observability/loki/loki-config.yaml
```yaml
---
server:
  http_listen_address: 0.0.0.0 # Địa chỉ IP mà Loki sẽ lắng nghe
  http_listen_port: 3100 # Cổng mà Loki sẽ lắng nghe

memberlist: # Cấu hình cho gossip
  join_members: ["read", "write", "backend"] # Các thành viên mà Loki sẽ tham gia vào gossip
  dead_node_reclaim_time: 30s # Thời gian mà Loki sẽ chờ để xóa một node đã chết
  gossip_to_dead_nodes_time: 15s # Thời gian mà Loki sẽ gửi gossip đến các node đã chết
  left_ingesters_timeout: 30s # Thời gian mà Loki sẽ chờ để xóa một ingester đã rời bỏ
  bind_addr: ['0.0.0.0'] # Địa chỉ IP mà Loki sẽ bind
  bind_port: 7946 # Cổng mà Loki sẽ bind
  gossip_interval: 2s # Thời gian mà Loki sẽ gửi gossip

schema_config: # Cấu hình cho schema
  configs:
    - from: 2021-08-01 # Thời gian bắt đầu của schema
      store: tsdb # Lưu trữ dữ liệu
      object_store: s3 # Lưu trữ dữ liệu trên S3
      schema: v13 # Phiên bản của schema
      index:
        prefix: index_ # Tiền tố của index
        period: 24h # Chu kỳ của index
common: # Cấu hình chung
  path_prefix: /loki # Tiền tố của path cho các API
  replication_factor: 1 # Số lượng replica
  compactor_address: http://backend:3100 # Địa chỉ của compactor để gửi dữ liệu
  storage: # Cấu hình cho storage lưu trữ dữ liệu
    s3: # Lưu trữ dữ liệu trên S3
      endpoint: minio:9000 # Địa chỉ của S3 endpoint, sử dụng MinIO, sẽ config trong docker-compose
      insecure: true # Sử dụng giao thức HTTP thay vì HTTPS
      bucketnames: loki-data # Tên của bucket lưu trữ dữ liệu
      access_key_id: loki # Access key ID của S3 sẽ config trong docker-compose
      secret_access_key: supersecret # Secret access key của S3 sẽ config trong docker-compose
      s3forcepathstyle: true # Sử dụng path style URL với mục đích tương thích với MinIO
  ring: # Cấu hình cho ring
    kvstore:
      store: memberlist # Lưu trữ thông tin của ring trên memberlist
ruler:
  storage:
    s3:
      bucketnames: loki-ruler # Tên của bucket lưu trữ dữ liệu cho ruler

compactor:
  working_directory: /tmp/compactor # Thư mục làm việc của compactor dùng để lưu trữ dữ liệu tạm thời
```

>observability/alloy/alloy-local-config.yaml
```yaml
  discovery.docker "flog_scrape" {
    host             = "unix:///var/run/docker.sock" 
    refresh_interval = "5s"
    }
    
    discovery.relabel "flog_scrape" {
    targets = []
    
    rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/(.*)"
    target_label  = "container" 
    }
  }
    
    loki.source.docker "flog_scrape" {
    host             = "unix:///var/run/docker.sock"
    targets          = discovery.docker.flog_scrape.targets
    forward_to       = [loki.write.default.receiver]
    relabel_rules    = discovery.relabel.flog_scrape.rules
    refresh_interval = "5s"
  }
    
    loki.write "default" {
    endpoint {
    url       = "http://gateway:3100/loki/api/v1/push"
    tenant_id = "tenant1"
    }
    external_labels = {}
  }
```
#### 2.2.3. Tạo file `docker-compose.yml` để chạy `Grafana Loki` với `Logs` từ `Microservices`
```yml
services:
  read: # Service read của Loki dùng để đọc dữ liệu từ các state của microservices
    image: grafana/loki:3.0.0 # Sử dụng image của Loki
    command: "-config.file=/etc/loki/config.yaml -target=read" # Command để chạy Loki
    ports:
      - 3101:3100
      - 7946
      - 9095
    volumes:
      - ../observability/loki/loki-config.yaml:/etc/loki/config.yaml # Mount file cấu hình vào container
    depends_on:
      - minio # Phụ thuộc vào service MinIO, một service lưu trữ dữ liệu
    healthcheck: # Kiểm tra sức khỏe của service
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: &loki-dns # Sử dụng & để gộp những dòng cấu hình này lại vào biến loki-dns
      didan: # Sử dụng network didan
        aliases: # Alias cho network
          - loki # Alias loki

  write: # Service write của Loki dùng để ghi dữ liệu từ các state của microservices
    image: grafana/loki:3.0.0 # Sử dụng image của Loki
    command: "-config.file=/etc/loki/config.yaml -target=write" # Command để chạy Loki
    ports:
      - 3102:3100
      - 7946
      - 9095
    volumes:
      - ../observability/loki/loki-config.yaml:/etc/loki/config.yaml # Mount file cấu hình vào container
    healthcheck: # Kiểm tra sức khỏe của service
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - minio # Phụ thuộc vào service MinIO, một service lưu trữ dữ liệu
    networks:
      <<: *loki-dns # Sử dụng biến loki-dns để gán network

  alloy: # Service alloy của Grafana dùng để xử lý dữ liệu từ Loki
    image: grafana/alloy-dev:latest # Sử dụng image của Alloy
    volumes:
      - ../observability/alloy/alloy-local-config.yaml:/etc/alloy/config.alloy:ro # Mount file cấu hình vào container với quyền read-only
      - /var/run/docker.sock:/var/run/docker.sock # Mount Docker socket vào container để Alloy có thể truy cập vào Docker
    command:  run --server.http.listen-addr=0.0.0.0:12345 --storage.path=/var/lib/alloy/data /etc/alloy/config.alloy # Command để chạy Alloy
    ports:
      - 12345:12345
    depends_on:
      - gateway # Phụ thuộc vào service gateway, điều hướng traffic hệ thống ghi logs
    networks:
      - didan # Sử dụng network didan

  minio: # Service MinIO dùng để lưu trữ dữ liệu của Loki
    image: minio/minio # Sử dụng image của MinIO
    entrypoint: # Command để chạy MinIO
      - sh
      - -euc
      - |
        mkdir -p /data/loki-data && \
        mkdir -p /data/loki-ruler && \
        minio server /data
    environment:
      - MINIO_ROOT_USER=loki # Username của MinIO
      - MINIO_ROOT_PASSWORD=supersecret # Password của MinIO
      - MINIO_PROMETHEUS_AUTH_TYPE=public # Cấu hình cho Prometheus
      - MINIO_UPDATE=off # Tắt cập nhật tự động
    ports:
      - 9000
    volumes:
      - ./.data/minio:/data # Mount volume để lưu trữ dữ liệu
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 15s
      timeout: 20s
      retries: 5
    networks:
      - didan

  grafana: # Service Grafana dùng để hiển thị dữ liệu từ Loki và xử lý dữ liệu từ Alloy
    image: grafana/grafana:latest # Sử dụng image của Grafana
    environment:
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning # Cấu hình cho provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true # Bật chế độ ẩn danh
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin # Phân quyền cho ẩn danh
    depends_on:
      - gateway # Phụ thuộc vào service gateway, điều hướng traffic hệ thống ghi logs
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /etc/grafana/provisioning/datasources
        cat <<EOF > /etc/grafana/provisioning/datasources/ds.yaml
        apiVersion: 1
        datasources:
          - name: Loki
            type: loki
            access: proxy
            url: http://gateway:3100
            jsonData:
              httpHeaderName1: "X-Scope-OrgID"
            secureJsonData:
              httpHeaderValue1: "tenant1"
        EOF
        /run.sh
    ports:
      - "3000:3000"
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - didan

  backend: # Service backend của Grafana dùng để xử lý dữ liệu từ Loki
    image: grafana/loki:3.0.0 # Sử dụng image của Loki
    volumes:
      - ../observability/loki/loki-config.yaml:/etc/loki/config.yaml # Mount file cấu hình vào container
    ports:
      - "3100"
      - "7946"
    command: "-config.file=/etc/loki/config.yaml -target=backend -legacy-read-mode=false" # Command để chạy backend
    depends_on:
      - gateway # Phụ thuộc vào service gateway, điều hướng traffic hệ thống ghi logs
    networks:
      - didan

  gateway: # Service gateway của Grafana dùng để điều hướng traffic hệ thống ghi logs
    image: nginx:latest # Sử dụng image của Nginx
    depends_on:
      - read # Phụ thuộc vào service read, dùng để đọc dữ liệu từ các state của microservices
      - write # Phụ thuộc vào service write, dùng để ghi dữ liệu từ các state của microservices
    entrypoint:
      - sh
      - -euc
      - |
        cat <<EOF > /etc/nginx/nginx.conf
        user  nginx;
        worker_processes  5;  ## Default: 1

        events {
          worker_connections   1000;
        }

        http {
          resolver 127.0.0.11;

          server {
            listen             3100;

            location = / {
              return 200 'OK';
              auth_basic off;
            }

            location = /api/prom/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /api/prom/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /api/prom/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }

            location = /loki/api/v1/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /loki/api/v1/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /loki/api/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }
          }
        }
        EOF
        /docker-entrypoint.sh nginx -g "daemon off;"
    ports:
      - "3100:3100"
    healthcheck: # Kiểm tra sức khỏe của service
      test: ["CMD", "service", "nginx", "status"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - didan

    ### Service Microservices

networks:
    didan: # Network didan dùng để kết nối các service trong hệ thống
        driver: bridge
```

SAU KHI CÀI ĐẶT XONG, CHÚNG TA CÓ THỂ TRUY CẬP VÀO `GRAFANA` TẠI `http://localhost:3000` ĐỂ XEM LOGS CỦA CÁC `MICROSERVICES` Ở TRONG MỤC `EXPLORE` CỦA `GRAFANA`. SAU ĐÓ CHÚNG TA CÓ THỂ TÌM KIẾM, LỌC VÀ TẠO BIỂU ĐỒ CHO LOGS.

## 3. Diễn giải các thông số `metrics` của `Actuator` trong `Spring Boot` với `Prometheus` bằng `Micrometer`
`Micrometer` là một thư viện giám sát hệ thống cho các ứng dụng Java. Nó cung cấp một cách tiêu chuẩn để thu thập các số liệu từ ứng dụng và gửi chúng đến các hệ thống giám sát như `Prometheus`, `Grafana`, `InfluxDB`,...

### 3.1. Cài đặt `Micrometer` và `Prometheus` trong `Spring Boot`
#### 3.1.1. Thêm `dependency` của `Actuator` và `Micrometer` vào file `pom.xml`:
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

#### 3.1.2. Thêm cấu vào `application.properties` để kích hoạt `Actuator` và `Metrics`.
Chúng ta thêm tất cả các cấu hình liên quan đến `Actuator` và `Micrometer` vào file `application.properties` của tất cả các ứng dụng trong `Microservices` kể cả `configserver`, `gatewayserver`,...
```yml
management:
  endpoints:
    web:
      exposure:
        include: "*"
  health:
    readiness-state:
      enabled: true
    liveness-state:
      enabled: true
  endpoint:
    shutdown:
      enabled: true
    health:
      probes:
        enabled: true
  info:
    env:
      enabled: true
  metrics:
    tags:
      application: ${spring.application.name} # Nhóm các metrics theo tên của service
```

SAU KHI CHẠY TẤT CẢ `SERVICE`, TRUY CẬP VÀO `/actuator/metrics` ĐỂ XEM CÁC `METRICS` CỦA `SERVICE`.

CÓ THỂ TRUY CẬP VÀO `/actuator/prometheus` ĐỂ XEM CÁC `METRICS` SẼ ĐƯỢC HỖ TRỢ DƯỚI DẠNG `PROMETHEUS` ĐỂ GỬI ĐẾN `PROMETHEUS` ĐỂ GIÁM SÁT.

### 3.2. Kết hợp `Prometheus` và `Grafana` để giám sát `Metrics` của `Spring Boot`
#### 3.2.1. Cấu hình file `prometheus.yml` để thu thập `Metrics` từ `Spring Boot Microservices`
>observability/prometheus/prometheus.yml
```yml
global: # Cấu hình chung cho tất cả các service
  scrape_interval:     5s # Thời gian để Prometheus lấy thông số metrics từ các service (5s)
  evaluation_interval: 5s # Thời gian để Prometheus đánh giá các thông số metrics (5s)

scrape_configs: # Cấu hình cho việc scrape metrics từ các service
  - job_name: 'accounts' # Tên của service (Thường trùng với tên của service spring.application.name)
    metrics_path: '/actuator/prometheus' # Endpoint để lấy metrics, mặc định là /actuator/prometheus sau khi cấu hình spring-boot-starter-actuator và micrometer-registry-prometheus
    static_configs: # Cấu hình cho việc scrape metrics từ
      - targets: [ 'accounts:8080' ] # Địa chỉ của service, dạng <tên-service>:<port-service>, do sử dụng docker-compose, join chung 1 mạng nên sử dụng tên của service để truy cập thay vì localhost
  - job_name: 'loans'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'loans:8090' ]
  - job_name: 'cards'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'cards:9000' ]
  - job_name: 'gatewayserver'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'gatewayserver:8072' ]
  - job_name: 'eurekaserver'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'eurekaserver:8070' ]
  - job_name: 'configserver'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'configserver:8071' ]
```

#### 3.2.2. Cấu hình file `docker-compose.yml` để chạy `Prometheus` và `Grafana`
Cấu hình file `docker-compose.yml` y như phần `#### 2.2.3. Tạo file docker-compose.yml để chạy Grafana Loki với Logs từ Microservices` nhưng thêm service `prometheus` và thêm thông số trong service `grafana` để kết nối với `Prometheus` ở phần `datasources` của `entrypoint`.

>Lưu ý: Cần thêm `deleteDatasources` trong `entrypoint` của `grafana` để xóa datasource tồn tại trước đó nếu có.
```yml
services:
 ...
 prometheus:
    image: prom/prometheus:v2.50.1 # Sử dụng image của Prometheus
    container_name: prometheus # Tên của container
    ports: 
      - "9090:9090" # Port để truy cập vào Prometheus
    volumes:
      - ../observability/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml # Mount file cấu hình vào container
    networks:
      - didan # Sử dụng network didan join chung với các service khác

 grafana: # Service Grafana dùng để hiển thị dữ liệu từ Loki và xử lý dữ liệu từ Alloy
    image: grafana/grafana:latest # Sử dụng image của Grafana
    environment:
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning # Cấu hình cho provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true # Bật chế độ ẩn danh
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin # Phân quyền cho ẩn danh
    depends_on:
      - gateway # Phụ thuộc vào service gateway, điều hướng traffic hệ thống ghi logs
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /etc/grafana/provisioning/datasources
        cat <<EOF > /etc/grafana/provisioning/datasources/ds.yaml
        apiVersion: 1
        deleteDatasources:
          - name: Prometheus
          - name: Loki
        datasources:
          - name: Loki
            type: loki
            access: proxy
            url: http://gateway:3100
            jsonData:
              httpHeaderName1: "X-Scope-OrgID"
            secureJsonData:
              httpHeaderValue1: "tenant1"
          - name: Prometheus
            type: prometheus
            uid: prometheus
            url: http://prometheus:9090
            access: proxy
            orgId: 1
            basicAuth: false
            isDefault: false
            version: 1
            editable: true
            jsonData:
              httpMethod: GET
        EOF
        /run.sh
    ports:
      - "3000:3000"
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - didan
...
```

SAU KHI CHẠY DOCKER COMPOSE, CHÚNG TA CÓ THỂ VÀO `http://localhost:9090` ĐỂ TRUY CẬP VÀO `PROMETHEUS` ĐỂ XEM CÁC `METRICS` CỦA CÁC `MICROSERVICES`.

NGOÀI RA, CHÚNG TA CÓ THỂ SỬ DỤNG `GRAFANA` ĐỂ HIỂN THỊ VÀ TẠO BIỂU ĐỒ CHO CÁC `METRICS` CỦA `MICROSERVICES` BẰNG CÁCH TRUY CẬP VÀO `http://localhost:3000` VÀ VÀO `EXPLORE` CHỌN `PROMETHEUS` ĐỂ XEM CÁC `METRICS` CỦA `MICROSERVICES`.

#### 3.2.3. Import `Dashboard` cho `Prometheus` và `Grafana`
Chúng ta có thể import các `Dashboard` cho `Prometheus` và `Grafana` để hiển thị `Metrics` của `Microservices` một cách dễ dàng.

Các `Dashboard` có thể tìm thấy tại: [Grafana Dashboard](https://grafana.com/grafana/dashboards) để tìm kiếm và import các `Dashboard` cho `Grafana`.

Ví dụ sau khi tìm `JVM (Micrometer)` trên `Grafana Dashboard` nhấn vào và copy `URL` của `Dashboard` sau đó vào `Grafana` đăng nhập với tài khoản mặc định `admin/admin` sau đó vào `Dashboard` chọn `Import` và paste `URL` vào ô `Grafana.com Dashboard` sau đó chọn `Prometheus` và nhấn `Load`.

## 4. Tạo `Alert` thông báo cho các thông số `Metrics` của `Microservices` với `Prometheus`.
Chúng ta có thể tạo `Alert` thông báo cho các `Metrics` của `Microservices` với `Prometheus` để nhận thông báo khi các `Metrics` vượt quá ngưỡng cho phép.

Có 2 cách tạo `Alert` thông báo trong `Grafana`:
- Sử dụng `Alert` trong `Grafana`: [Create Alerts & Send notifications using Grafana - Use Alert Options](https://youtu.be/eNkNMnaxsJA)
- Sử dụng `Alert` trong `Dashboard` của `Grafana`: [Create Alerts & Send notifications using Grafana - Use Dashboard Monitor](https://youtu.be/JIYP0oIY0Fc)

## 5. Tạo `Traces` cho `Microservices` để truy vết các request trong hệ thống.
`Traces` giúp chúng ta theo dõi các request từ khi bắt đầu cho đến khi kết thúc và xác định các vấn đề nếu có.

Chúng ta sẽ tạo một cấu trúc cho `traces` phân phối cho các `Microservices` trong hệ thống để theo dõi các request. Cấu trúc sẽ là `[(name-service), (trace-id), (span-id)]`, trong đó:
- `name-service`: Tên của service giúp xác định service đang xử lý request.
- `trace-id`: ID của trace giúp xác định request đang xử lý, tất cả các `sevice` được gọi trong 1 request sẽ có cùng `trace-id`.
- `span-id`: ID của span giúp xác định các bước xử lý của request, mỗi bước xử lý trong từng service sẽ có một `span-id` riêng.

Chúng ta sẽ sử dụng `OpenTelemetry` để tạo `Traces` cho `Microservices` trong hệ thống. Vì `OpenTelemetry` hỗ trợ nhiều ngôn ngữ lập trình nên chúng ta có thể sử dụng `OpenTelemetry` cho các ứng dụng viết bằng `Java`, `Python`, `Go`,...

Tiếp theo, chúng ta sẽ sử dụng container `Tempo` để lưu trữ và hiển thị `Traces` của `Microservices` trong hệ thống.

Cuối cùng, chúng ta sẽ sử dụng `Grafana` để hiển thị `Traces` của `Microservices` trong hệ thống.

### 5.1. Cài đặt `OpenTelemetry` trong `Microservices`
Có thể tham khảo tại: [Java Agent | OpenTelemetry](https://opentelemetry.io/docs/zero-code/java/agent/)

Chúng ta thêm thuộc tính `<otelVersion>` vào thẻ `<properties>` trong file `pom.xml` của `Microservices` để thiết lập phiên bản của `OpenTelemetry`.

Sau đó thêm `dependency` của `OpenTelemetry` vào file `pom.xml` của `Microservices`:
>pom.xml
```xml
...
<properties>
    ...
    <otelVersion>1.7.0</otelVersion>
</properties>

<dendencies>
    ...
    <dependency>
        <groupId>io.opentelemetry.javaagent</groupId>
        <artifactId>opentelemetry-javaagent</artifactId>
        <version>${otelVersion}</version>
        <scope>runtime</scope>
    </dependency>
</dependencies>
...
```

### 5.2. Cấu hình định dạng `logs` trong `application.yml` của `Microservices` để tạo `Traces`
Chúng ta cấu hình định dạng `logs` trong `application.yml` của `Microservices` để tạo `Traces` cho `Microservices` theo cấu trúc `[(name-service), (trace-id), (span-id)]`.
>application.yml
```yml
logging:
  level:
    com:
      didan:
        accounts: DEBUG
  pattern:
    level: "%5p [${spring.application.name},%X{trace_id},%X{span_id}]"
```
Trong đó:
- `%5p`: Level của log, ví dụ: `INFO`, `ERROR`,...
- `${spring.application.name}`: Tên của service.
- `%X{trace_id}`: Trace ID của request. `%X` là một `MDC` (Mapped Diagnostic Context) giúp lưu trữ các thông tin của request.
- `%X{span_id}`: Span ID của request, giống như `trace_id`.

