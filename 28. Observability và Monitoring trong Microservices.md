# Observability và Monitoring trong Microservices
## 1. Giới thiệu
### 1.1. Observability
`Observability` là khả năng hiểu trạng thái bên trong của hệ thống dựa trên các dữ liệu đầu ra.

Trong `Microservices`, observability có được bởi việc thu thấp, phân tích dữ liệu từ nhiều nguồn khác nhau như logs, metrics, traces.
- `Metrics`: Đơn vị đo lường sức khỏe của hệ thống. Chúng được sư dụng để theo dõi các số liệu như: `mức độ sử dụng CPU`, `lưu lượng mạng`, `số lượng request`, `thời gian xử lý request`,...
- `Logs`: Sẽ ghi lại các sự kiện xảy ra trong hệ thống. Chúng được sử dụng để theo dõi các sự kiện như: `lỗi`, `thông báo`, `cảnh báo`, `exception`, `các sự kiện không lường trước`,...
- `Traces`: Ghi lại các đường dẫn mà 1 request đi qua trong hệ thống. Chúng được sử dụng để theo dõi hiệu năng của 1 request và xác định các vấn đề nếu có.

### 1.2. Monitoring
`Monitoring` trong `Microservices` tham gia vào việc kiểm tra các dữ liệu có sẵn từ `Observability` và tạo ra các cảnh báo cho các trạng thái thất bại hoặc không bình thường.

Quá trình này thu thập và phân tích dữ liệu từ hệ thống để xác định và troubleshoot các vấn đề.

`Monitoring` rất quan trọng trong `Microservices` vì nó cho phép:
- `Identify and troubleshoot problems`: Bằng việc thu thập và phân tích dữ liệu từ hệ thống, chúng ta có thể xác định và giải quyết các vấn đề.
- `Track the health of microservices`: Chúng ta có thể theo dõi sức khỏe của các microservices và xác định các vấn đề trước khi chúng trở nên nghiêm trọng.
- `Optimize microservices`: Có thể xác định những khu vực cần cải thiện và tối ưu hóa hiệu suất của hệ thống.

### 1.3. Sự khác biệt giữa Observability và Monitoring
| Tính năng | Monitoring | Observability |
|:---------:|:----------:|:-------------:|
| Mục đích | Xác định và giải quyết vấn đề | Hiểu rõ các trạng thái bên trong hệ thống |
| Dữ liệu | Dữ liệu cụ thể (Metrics, traces, log) | Gồm nhiều dữ liệu đa dạng |
| Cách tiếp cận | Phản ứng khi có vấn đề | Proactive, chủ động phát hiện vấn đề |

## 2. Quản lý logs trong Microservices với `Grafana Loki & Promtail`
### 2.1. Giới thiệu
`Grafana Loki` là một hệ thống thu thập và lưu trữ logs cho các hệ thống phân tán. Nó được thiết kế để hoạt động với `Prometheus` và `Grafana` để cung cấp một giải pháp giám sát hoàn chỉnh cho hệ thống.


`Promtail` là một `agent` thu thập logs từ các `Microservices` sau đó `xử lý` và `chuyển tiếp` logs đến `Loki`.

`Loki` sẽ `lưu trữ` và `tổng hợp` logs từ `Promtail` và cung cấp các `truy vấn`, `tìm kiếm` logs hiệu quả đến `Grafana`.

`Grafana` sẽ `hiển thị` và `tạo biểu đồ` logs từ `Loki` để giúp người dùng dễ dàng theo dõi và phân tích logs.

### 2.2. Cài đặt với Docker Compose
Tham khảo tại: [Grafana Loki Get Started](https://grafana.com/docs/loki/latest/get-started/quick-start/)
#### 2.2.1. Luồng hoạt động cua `Grafana Loki` với các container
Đê chạy `Grafana Loki` với `Docker Compose`, chúng ta cần có các `container` sau:
1. `Microservices`: Đây là các `container` chứa các `Microservices` cần thu thập logs.
2. `Grafana Alloy`: Thu thập các dòng `logs` từ các `Microservices` và chuyển tiếp đến `Loki` thông qua các cổng `port`
3. `Gateway (NGINX)`: Nhận các request và chuyển tiếp chúng tới các `container` khác trong hệ thống `Grafana Loki`.
4. `Loki read`: Đọc, truy vấn các `logs` từ `Loki` và hiển thị chúng trên `Grafana`.
5. `Loki write`: Nhận các `logs` từ `Grafana Alloy` và lưu trữ chúng vào `Loki`.
6. `Loki backend`: Xử lý dữ liệu của `Grafana` bao gồm các components như `Index Gateway`, `Compactor`, `Ruler`, `Bloom Compactor (Experimental)`, `Bloom Gateway (Experimental)`.
7. `Minio`: Một `object storage` S3-compatible để lưu trữ dữ liệu của `Loki`.
8. `Grfana`: Hiển thị và tạo biểu đồ logs từ `Loki`.

#### 2.2.2. Tạo các file `yaml` cấu hình cho `Loki`, `Alloy` và `Grfana`
>observability/loki/loki-config.yaml
```yaml
---
server:
  http_listen_address: 0.0.0.0 # Địa chỉ IP mà Loki sẽ lắng nghe
  http_listen_port: 3100 # Cổng mà Loki sẽ lắng nghe

memberlist: # Cấu hình cho gossip
  join_members: ["read", "write", "backend"] # Các thành viên mà Loki sẽ tham gia vào gossip
  dead_node_reclaim_time: 30s # Thời gian mà Loki sẽ chờ để xóa một node đã chết
  gossip_to_dead_nodes_time: 15s # Thời gian mà Loki sẽ gửi gossip đến các node đã chết
  left_ingesters_timeout: 30s # Thời gian mà Loki sẽ chờ để xóa một ingester đã rời bỏ
  bind_addr: ['0.0.0.0'] # Địa chỉ IP mà Loki sẽ bind
  bind_port: 7946 # Cổng mà Loki sẽ bind
  gossip_interval: 2s # Thời gian mà Loki sẽ gửi gossip

schema_config: # Cấu hình cho schema
  configs:
    - from: 2021-08-01 # Thời gian bắt đầu của schema
      store: tsdb # Lưu trữ dữ liệu
      object_store: s3 # Lưu trữ dữ liệu trên S3
      schema: v13 # Phiên bản của schema
      index:
        prefix: index_ # Tiền tố của index
        period: 24h # Chu kỳ của index
common: # Cấu hình chung
  path_prefix: /loki # Tiền tố của path cho các API
  replication_factor: 1 # Số lượng replica
  compactor_address: http://backend:3100 # Địa chỉ của compactor để gửi dữ liệu
  storage: # Cấu hình cho storage lưu trữ dữ liệu
    s3: # Lưu trữ dữ liệu trên S3
      endpoint: minio:9000 # Địa chỉ của S3 endpoint, sử dụng MinIO, sẽ config trong docker-compose
      insecure: true # Sử dụng giao thức HTTP thay vì HTTPS
      bucketnames: loki-data # Tên của bucket lưu trữ dữ liệu
      access_key_id: loki # Access key ID của S3 sẽ config trong docker-compose
      secret_access_key: supersecret # Secret access key của S3 sẽ config trong docker-compose
      s3forcepathstyle: true # Sử dụng path style URL với mục đích tương thích với MinIO
  ring: # Cấu hình cho ring
    kvstore:
      store: memberlist # Lưu trữ thông tin của ring trên memberlist
ruler:
  storage:
    s3:
      bucketnames: loki-ruler # Tên của bucket lưu trữ dữ liệu cho ruler

compactor:
  working_directory: /tmp/compactor # Thư mục làm việc của compactor dùng để lưu trữ dữ liệu tạm thời
```

>observability/alloy/alloy-local-config.yaml
```yaml
  discovery.docker "flog_scrape" {
    host             = "unix:///var/run/docker.sock" 
    refresh_interval = "5s"
    }
    
    discovery.relabel "flog_scrape" {
    targets = []
    
    rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/(.*)"
    target_label  = "container" 
    }
  }
    
    loki.source.docker "flog_scrape" {
    host             = "unix:///var/run/docker.sock"
    targets          = discovery.docker.flog_scrape.targets
    forward_to       = [loki.write.default.receiver]
    relabel_rules    = discovery.relabel.flog_scrape.rules
    refresh_interval = "5s"
  }
    
    loki.write "default" {
    endpoint {
    url       = "http://gateway:3100/loki/api/v1/push"
    tenant_id = "tenant1"
    }
    external_labels = {}
  }
```
>observability/grafana/grafana-config.yml
```yml
apiVersion: 1

deleteDatasources: # Xóa tất cả các datasource trước khi tạo datasource mới
  - name: Loki

datasources: # Tạo datasource mới
  - name: Loki # Tên datasource
    type: loki
    uid: loki
    access: proxy
    orgId: 1
    editable: true
    url: http://gateway:3100 # URL của Loki lấy từ gateway service trong docker-compose.yml
    jsonData:
      httpHeaderName1: "X-Scope-OrgID" # Header name
    secureJsonData: # Dữ liệu JSON bảo mật
      httpHeaderValue1: "tenant1"
```
#### 2.2.3. Tạo file `docker-compose.yml` để chạy `Grafana Loki` với `Logs` từ `Microservices`
```yml
services:
  read: # Service read của Loki dùng để đọc dữ liệu từ các state của microservices
    image: grafana/loki:3.0.0 # Sử dụng image của Loki
    command: "-config.file=/etc/loki/config.yaml -target=read" # Command để chạy Loki
    ports:
      - 3101:3100
      - 7946
      - 9095
    volumes:
      - ../observability/loki/loki-config.yaml:/etc/loki/config.yaml # Mount file cấu hình vào container
    depends_on:
      - minio # Phụ thuộc vào service MinIO, một service lưu trữ dữ liệu
    healthcheck: # Kiểm tra sức khỏe của service
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: &loki-dns # Sử dụng & để gộp những dòng cấu hình này lại vào biến loki-dns
      didan: # Sử dụng network didan
        aliases: # Alias cho network
          - loki # Alias loki

  write: # Service write của Loki dùng để ghi dữ liệu từ các state của microservices
    image: grafana/loki:3.0.0 # Sử dụng image của Loki
    command: "-config.file=/etc/loki/config.yaml -target=write" # Command để chạy Loki
    ports:
      - 3102:3100
      - 7946
      - 9095
    volumes:
      - ../observability/loki/loki-config.yaml:/etc/loki/config.yaml # Mount file cấu hình vào container
    healthcheck: # Kiểm tra sức khỏe của service
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - minio # Phụ thuộc vào service MinIO, một service lưu trữ dữ liệu
    networks:
      <<: *loki-dns # Sử dụng biến loki-dns để gán network

  alloy: # Service alloy của Grafana dùng để xử lý dữ liệu từ Loki
    image: grafana/alloy-dev:latest # Sử dụng image của Alloy
    volumes:
      - ../observability/alloy/alloy-local-config.yaml:/etc/alloy/config.alloy:ro # Mount file cấu hình vào container với quyền read-only
      - /var/run/docker.sock:/var/run/docker.sock # Mount Docker socket vào container để Alloy có thể truy cập vào Docker
    command:  run --server.http.listen-addr=0.0.0.0:12345 --storage.path=/var/lib/alloy/data /etc/alloy/config.alloy # Command để chạy Alloy
    ports:
      - 12345:12345
    depends_on:
      - gateway # Phụ thuộc vào service gateway, điều hướng traffic hệ thống ghi logs
    networks:
      - didan # Sử dụng network didan

  minio: # Service MinIO dùng để lưu trữ dữ liệu của Loki
    image: minio/minio # Sử dụng image của MinIO
    entrypoint: # Command để chạy MinIO
      - sh
      - -euc
      - |
        mkdir -p /data/loki-data && \
        mkdir -p /data/loki-ruler && \
        minio server /data
    environment:
      - MINIO_ROOT_USER=loki # Username của MinIO
      - MINIO_ROOT_PASSWORD=supersecret # Password của MinIO
      - MINIO_PROMETHEUS_AUTH_TYPE=public # Cấu hình cho Prometheus
      - MINIO_UPDATE=off # Tắt cập nhật tự động
    ports:
      - 9000
    volumes:
      - ./.data/minio:/data # Mount volume để lưu trữ dữ liệu
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 15s
      timeout: 20s
      retries: 5
    networks:
      - didan

  grafana: # Service Grafana dùng để hiển thị dữ liệu từ Loki và xử lý dữ liệu từ Alloy
    image: grafana/grafana:latest # Sử dụng image của Grafana
    environment:
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning # Cấu hình cho provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true # Bật chế độ ẩn danh
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin # Phân quyền cho ẩn danh
    depends_on:
      - gateway # Phụ thuộc vào service gateway, điều hướng traffic hệ thống ghi logs
    entrypoint:
      - sh
      - -euc
      - |
        /run.sh
    ports:
      - "3000:3000"
    volumes:
      - ../observability/grafana/grafana-config.yml:/etc/grafana/provisioning/datasources/ds.yml # Mount file cấu hình vào container
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - didan

  backend: # Service backend của Grafana dùng để xử lý dữ liệu từ Loki
    image: grafana/loki:3.0.0 # Sử dụng image của Loki
    volumes:
      - ../observability/loki/loki-config.yaml:/etc/loki/config.yaml # Mount file cấu hình vào container
    ports:
      - "3100"
      - "7946"
    command: "-config.file=/etc/loki/config.yaml -target=backend -legacy-read-mode=false" # Command để chạy backend
    depends_on:
      - gateway # Phụ thuộc vào service gateway, điều hướng traffic hệ thống ghi logs
    networks:
      - didan

  gateway: # Service gateway của Grafana dùng để điều hướng traffic hệ thống ghi logs
    image: nginx:latest # Sử dụng image của Nginx
    depends_on:
      - read # Phụ thuộc vào service read, dùng để đọc dữ liệu từ các state của microservices
      - write # Phụ thuộc vào service write, dùng để ghi dữ liệu từ các state của microservices
    entrypoint:
      - sh
      - -euc
      - |
        cat <<EOF > /etc/nginx/nginx.conf
        user  nginx;
        worker_processes  5;  ## Default: 1

        events {
          worker_connections   1000;
        }

        http {
          resolver 127.0.0.11;

          server {
            listen             3100;

            location = / {
              return 200 'OK';
              auth_basic off;
            }

            location = /api/prom/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /api/prom/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /api/prom/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }

            location = /loki/api/v1/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /loki/api/v1/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /loki/api/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }
          }
        }
        EOF
        /docker-entrypoint.sh nginx -g "daemon off;"
    ports:
      - "3100:3100"
    healthcheck: # Kiểm tra sức khỏe của service
      test: ["CMD", "service", "nginx", "status"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - didan

    ### Service Microservices

networks:
    didan: # Network didan dùng để kết nối các service trong hệ thống
        driver: bridge
```

SAU KHI CÀI ĐẶT XONG, CHÚNG TA CÓ THỂ TRUY CẬP VÀO `GRAFANA` TẠI `http://localhost:3000` ĐỂ XEM LOGS CỦA CÁC `MICROSERVICES` Ở TRONG MỤC `EXPLORE` CỦA `GRAFANA`. SAU ĐÓ CHÚNG TA CÓ THỂ TÌM KIẾM, LỌC VÀ TẠO BIỂU ĐỒ CHO LOGS.

## 3. Diễn giải các thông số `metrics` của `Actuator` trong `Spring Boot` với `Prometheus` bằng `Micrometer`
`Micrometer` là một thư viện giám sát hệ thống cho các ứng dụng Java. Nó cung cấp một cách tiêu chuẩn để thu thập các số liệu từ ứng dụng và gửi chúng đến các hệ thống giám sát như `Prometheus`, `Grafana`, `InfluxDB`,...

### 3.1. Cài đặt `Micrometer` và `Prometheus` trong `Spring Boot`
#### 3.1.1. Thêm `dependency` của `Actuator` và `Micrometer` vào file `pom.xml`:
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

#### 3.1.2. Thêm cấu vào `application.properties` để kích hoạt `Actuator` và `Metrics`.
Chúng ta thêm tất cả các cấu hình liên quan đến `Actuator` và `Micrometer` vào file `application.properties` của tất cả các ứng dụng trong `Microservices` kể cả `configserver`, `gatewayserver`,...
```yml
management:
  endpoints:
    web:
      exposure:
        include: "*"
  health:
    readiness-state:
      enabled: true
    liveness-state:
      enabled: true
  endpoint:
    shutdown:
      enabled: true
    health:
      probes:
        enabled: true
  info:
    env:
      enabled: true
  metrics:
    tags:
      application: ${spring.application.name} # Nhóm các metrics theo tên của service
```

SAU KHI CHẠY TẤT CẢ `SERVICE`, TRUY CẬP VÀO `/actuator/metrics` ĐỂ XEM CÁC `METRICS` CỦA `SERVICE`.

CÓ THỂ TRUY CẬP VÀO `/actuator/prometheus` ĐỂ XEM CÁC `METRICS` SẼ ĐƯỢC HỖ TRỢ DƯỚI DẠNG `PROMETHEUS` ĐỂ GỬI ĐẾN `PROMETHEUS` ĐỂ GIÁM SÁT.

### 3.2. Kết hợp `Prometheus` và `Grafana` để giám sát `Metrics` của `Spring Boot`
#### 3.2.1. Cấu hình file `prometheus.yml` để thu thập `Metrics` từ `Spring Boot Microservices`
>observability/prometheus/prometheus.yml
```yml
global: # Cấu hình chung cho tất cả các service
  scrape_interval:     5s # Thời gian để Prometheus lấy thông số metrics từ các service (5s)
  evaluation_interval: 5s # Thời gian để Prometheus đánh giá các thông số metrics (5s)

scrape_configs: # Cấu hình cho việc scrape metrics từ các service
  - job_name: 'accounts' # Tên của service (Thường trùng với tên của service spring.application.name)
    metrics_path: '/actuator/prometheus' # Endpoint để lấy metrics, mặc định là /actuator/prometheus sau khi cấu hình spring-boot-starter-actuator và micrometer-registry-prometheus
    static_configs: # Cấu hình cho việc scrape metrics từ
      - targets: [ 'accounts:8080' ] # Địa chỉ của service, dạng <tên-service>:<port-service>, do sử dụng docker-compose, join chung 1 mạng nên sử dụng tên của service để truy cập thay vì localhost
  - job_name: 'loans'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'loans:8090' ]
  - job_name: 'cards'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'cards:9000' ]
  - job_name: 'gatewayserver'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'gatewayserver:8072' ]
  - job_name: 'eurekaserver'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'eurekaserver:8070' ]
  - job_name: 'configserver'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: [ 'configserver:8071' ]
```

#### 3.2.2. Cấu hình file `docker-compose.yml` để chạy `Prometheus` và `Grafana`
Cấu hình file `grafana-config.yml` y như phần `#### 2.2.2. Tạo các file yaml cấu hình cho Loki, Alloy và Grfana` nhưng thêm service `prometheus` và thêm thông số trong service `grafana` để kết nối với `Prometheus` ở phần `datasources`.

>grafana-config.yml
```yml
apiVersion: 1

deleteDatasources: # Xóa tất cả các datasource trước khi tạo datasource mới
  - name: Prometheus
  - name: Loki
  - name: Tempo

datasources: # Tạo datasource mới
  - name: Prometheus # Tên datasource
    type: prometheus # Loại datasource
    uid: prometheus # UID của datasource
    url: http://prometheus:9090 # URL của datasource, trùng với tên service trong docker-compose.yml
    access: proxy # Quyền truy cập
    orgId: 1 # ID của organization
    basicAuth: false # Sử dụng basic auth hay không
    isDefault: false # Đặt datasource này là datasource mặc định hay không
    version: 1 # Phiên bản của datasource
    editable: true # Có thể chỉnh sửa datasource hay không
    jsonData: # Dữ liệu JSON
      httpMethod: GET # Phương thức HTTP
  - name: Loki # Tên datasource
    type: loki
    uid: loki
    access: proxy
    orgId: 1
    editable: true
    url: http://gateway:3100 # URL của Loki lấy từ gateway service trong docker-compose.yml
    jsonData:
      httpHeaderName1: "X-Scope-OrgID" # Header name
    secureJsonData: # Dữ liệu JSON bảo mật
      httpHeaderValue1: "tenant1"
```

SAU KHI CHẠY DOCKER COMPOSE, CHÚNG TA CÓ THỂ VÀO `http://localhost:9090` ĐỂ TRUY CẬP VÀO `PROMETHEUS` ĐỂ XEM CÁC `METRICS` CỦA CÁC `MICROSERVICES`.

NGOÀI RA, CHÚNG TA CÓ THỂ SỬ DỤNG `GRAFANA` ĐỂ HIỂN THỊ VÀ TẠO BIỂU ĐỒ CHO CÁC `METRICS` CỦA `MICROSERVICES` BẰNG CÁCH TRUY CẬP VÀO `http://localhost:3000` VÀ VÀO `EXPLORE` CHỌN `PROMETHEUS` ĐỂ XEM CÁC `METRICS` CỦA `MICROSERVICES`.

#### 3.2.3. Import `Dashboard` cho `Prometheus` và `Grafana`
Chúng ta có thể import các `Dashboard` cho `Prometheus` và `Grafana` để hiển thị `Metrics` của `Microservices` một cách dễ dàng.

Các `Dashboard` có thể tìm thấy tại: [Grafana Dashboard](https://grafana.com/grafana/dashboards) để tìm kiếm và import các `Dashboard` cho `Grafana`.

Ví dụ sau khi tìm `JVM (Micrometer)` trên `Grafana Dashboard` nhấn vào và copy `URL` của `Dashboard` sau đó vào `Grafana` đăng nhập với tài khoản mặc định `admin/admin` sau đó vào `Dashboard` chọn `Import` và paste `URL` vào ô `Grafana.com Dashboard` sau đó chọn `Prometheus` và nhấn `Load`.

## 4. Tạo `Alert` thông báo cho các thông số `Metrics` của `Microservices` với `Prometheus`.
Chúng ta có thể tạo `Alert` thông báo cho các `Metrics` của `Microservices` với `Prometheus` để nhận thông báo khi các `Metrics` vượt quá ngưỡng cho phép.

Có 2 cách tạo `Alert` thông báo trong `Grafana`:
- Sử dụng `Alert` trong `Grafana`: [Create Alerts & Send notifications using Grafana - Use Alert Options](https://youtu.be/eNkNMnaxsJA)
- Sử dụng `Alert` trong `Dashboard` của `Grafana`: [Create Alerts & Send notifications using Grafana - Use Dashboard Monitor](https://youtu.be/JIYP0oIY0Fc)

## 5. Tạo `Traces` cho `Microservices` để truy vết các request trong hệ thống.
`Traces` giúp chúng ta theo dõi các request từ khi bắt đầu cho đến khi kết thúc và xác định các vấn đề nếu có.

Chúng ta sẽ tạo một cấu trúc cho `traces` phân phối cho các `Microservices` trong hệ thống để theo dõi các request. Cấu trúc sẽ là `[(name-service), (trace-id), (span-id)]`, trong đó:
- `name-service`: Tên của service giúp xác định service đang xử lý request.
- `trace-id`: ID của trace giúp xác định request đang xử lý, tất cả các `sevice` được gọi trong 1 request sẽ có cùng `trace-id`.
- `span-id`: ID của span giúp xác định các bước xử lý của request, mỗi bước xử lý trong từng service sẽ có một `span-id` riêng.

Chúng ta sẽ sử dụng `OpenTelemetry` để tạo `Traces` cho `Microservices` trong hệ thống. Vì `OpenTelemetry` hỗ trợ nhiều ngôn ngữ lập trình nên chúng ta có thể sử dụng `OpenTelemetry` cho các ứng dụng viết bằng `Java`, `Python`, `Go`,...

Tiếp theo, chúng ta sẽ sử dụng container `Tempo` để lưu trữ và hiển thị `Traces` của `Microservices` trong hệ thống.

Cuối cùng, chúng ta sẽ sử dụng `Grafana` để hiển thị `Traces` của `Microservices` trong hệ thống.

### 5.1. Cài đặt `OpenTelemetry` trong `Microservices`
Có thể tham khảo tại: [Java Agent | OpenTelemetry](https://opentelemetry.io/docs/zero-code/java/agent/)

Chúng ta thêm thuộc tính `<otelVersion>` vào thẻ `<properties>` trong file `pom.xml` của `Microservices` để thiết lập phiên bản của `OpenTelemetry`.

> **LƯU Ý: NÊN CÀI BẢN 1.X TRÁNH 2.X ĐỂ KHÔNG BỊ LỖI, CỤ THỂ SẼ CÀI 1.32.0.**

Sau đó thêm `dependency` của `OpenTelemetry` vào file `pom.xml` của `Microservices`:
>pom.xml
```xml
...
<properties>
    ...
    <otelVersion>1.32.0</otelVersion>
</properties>

<dendencies>
    ...
    <dependency>
        <groupId>io.opentelemetry.javaagent</groupId>
        <artifactId>opentelemetry-javaagent</artifactId>
        <version>${otelVersion}</version>
        <scope>runtime</scope>
    </dependency>
</dependencies>
...
```

### 5.2. Cấu hình định dạng `logs` trong `application.yml` của `Microservices` để tạo `Traces`
Chúng ta cấu hình định dạng `logs` trong `application.yml` của `Microservices` để tạo `Traces` cho `Microservices` theo cấu trúc `[(name-service), (trace-id), (span-id)]`.
>application.yml
```yml
logging:
  level:
    com:
      didan:
        accounts: DEBUG
  pattern:
    level: "%5p [${spring.application.name},%X{trace_id},%X{span_id}]"
```
Trong đó:
- `%5p`: Level của log, ví dụ: `INFO`, `ERROR`,...
- `${spring.application.name}`: Tên của service.
- `%X{trace_id}`: Trace ID của request. `%X` là một `MDC` (Mapped Diagnostic Context) giúp lưu trữ các thông tin của request. Nhờ `OpenTelemetry` mà `trace_id`, `span_id` sẽ được tự động thêm vào `MDC` của `logs`.
- `%X{span_id}`: Span ID của request, giống như `trace_id`.

**Sau đó, tiến hành đặt `logs` vào trong `code` của `Microservices` để tạo `Traces` cho `Microservices`. Khi tạo ra một `log` mới, máy sẽ tự thêm `trace_id` và `span_id` vào `MDC` để lưu trữ các thông tin của request.**

### 5.3. Cấu hình Docker Compose cho `OpenTelemetry Javaagent` + Cài đặt `Tempo` kết hợp với `Grafana` để lưu trữ và hiển thị `Traces` của `Microservices`.
#### 5.3.1. Cấu hình `OpenTelemetry Javaagent` trong `Docker Compose`
Để chạy `OpenTelemetry Javaagent` chúng ta thêm các biến môi trường vào tất cả các `service` của `Microservices` trong `Docker Compose` để kích hoạt `OpenTelemetry Javaagent` như sau:
> `OTEL_SERVICE_NAME`: Tên của `service` phải trùng với tên `service trong Docker Compose` để xác định `service` đang xử lý request.
```yml
environment:
 OTEL_SERVICE_NAME: "accounts"
```
> `JAVA_TOOL_OPTIONS`: Chọn file `.jar` của `OpenTelemetry Javaagent` để chạy. Mặc định trong `Docker Container`, các thư viện sẽ được nằm trong thư mục `/app/libs` nên chúng ta sẽ chọn file `.jar` của `OpenTelemetry Javaagent` trong thư mục `/app/libs`.
```yml
environment:
 JAVA_TOOL_OPTIONS: "javaagent:/app/libs/opentelemetry-javaagent-{version}.jar"
```
> `OTEL_EXPORTER_OTLP_ENDPOINT`: Địa chỉ của `Tempo` để lưu trữ `Traces` của `Microservices`. Chúng ta sẽ map đến `Tempo` trong `Docker Compose`.
```yml
environment:
 OTEL_EXPORTER_OTLP_ENDPOINT: "http://tempo:4317"
```
> `OTEL_METRICS_EXPORTER`: Chọn `exporter` cho `Metrics` của `OpenTelemetry`. Chúng ta sẽ chọn `Prometheus` để lưu trữ `Metrics` của `Microservices`, nên phần này sẽ để `NONE` để không lưu trữ `Metrics` của `OpenTelemetry`.
```yml
environment:
 OTEL_METRICS_EXPORTER: "none"
```

#### 5.3.2. Cài đặt `Tempo` trong `Docker Compose`
Đầu tiên, chúng ta cần tạo file `yaml` cấu hình cho `Tempo`, nên để các thông số mặc định của `Tempo`:
>observability/tempo/tempo-config.yml
```yml
server:
  http_listen_port: 3100

distributor:
  receivers:
    otlp:
      protocols:
        grpc:
        http:

ingester:
  trace_idle_period: 10s
  max_block_bytes: 1_000_000
  max_block_duration: 5m

compactor:
  compaction:
    compaction_window: 1h
    max_compaction_objects: 1000000
    block_retention: 1h
    compacted_block_retention: 10m

storage:
  trace:
    backend: local
    local:
      path: /tmp/tempo/blocks
    pool:
      max_workers: 100
      queue_depth: 10000
```

Tiếp theo, chúng ta cần cài đặt `Tempo` để lưu trữ `Traces` của `Microservices` trong hệ thống. Chúng ta sẽ sử dụng `Docke Compose` để cài đặt `Tempo`:
```yml
services:
  tempo:
    image: grafana/tempo
    container_name: tempo
    command: -config.file /etc/tempo-config.yml # Command để chạy Tempo
    ports:
      - "3110:3100" # Port để truy cập vào Tempo, chú ý map port phải không trùng với port của các service khác
      - "4317:4317" # Port để lưu trữ Traces của Microservices trong Tempo
    volumes:
      - ../observability/tempo/tempo-config.yml:/etc/tempo-config.yml # Mount file cấu hình vào container
    networks:
      - didan # Phải join chung network với các service khác
```

Cuối cùng, thêm profiles của `Tempo` vào `datasources` của file cấu hình `grafana-config.yml` để hiển thị `Traces` của `Microservices` trong hệ thống: (Sử dụng `grafana` từ phần `#### 3.3.2`)
```yml
apiVersion: 1

deleteDatasources: # Xóa tất cả các datasource trước khi tạo datasource mới
  - name: Prometheus
  - name: Loki
  - name: Tempo

datasources: # Tạo datasource mới
  - name: Prometheus # Tên datasource
    type: prometheus # Loại datasource
    uid: prometheus # UID của datasource
    url: http://prometheus:9090 # URL của datasource, trùng với tên service trong docker-compose.yml
    access: proxy # Quyền truy cập
    orgId: 1 # ID của organization
    basicAuth: false # Sử dụng basic auth hay không
    isDefault: false # Đặt datasource này là datasource mặc định hay không
    version: 1 # Phiên bản của datasource
    editable: true # Có thể chỉnh sửa datasource hay không
    jsonData: # Dữ liệu JSON
      httpMethod: GET # Phương thức HTTP
  - name: Tempo # Tên datasource
    type: tempo # Loại datasource
    uid: tempo
    url: http://tempo:3100 # URL của Tempo lấy từ service trong docker-compose.yml
    access: proxy
    orgId: 1
    basicAuth: false
    isDefault: false
    version: 1
    editable: true
    jsonData:
      httpMethod: GET
      serviceMap: # Bản đồ dịch vụ của Tempo
        datasourceUid: 'prometheus' # UID của datasource Prometheus để lấy dữ liệu
  - name: Loki # Tên datasource
    type: loki
    uid: loki
    access: proxy
    orgId: 1
    editable: true
    url: http://gateway:3100 # URL của Loki lấy từ gateway service trong docker-compose.yml
    jsonData:
      httpHeaderName1: "X-Scope-OrgID" # Header name
    secureJsonData: # Dữ liệu JSON bảo mật
      httpHeaderValue1: "tenant1"
```

SAU KHI CHẠY TẤT CẢ `SERVICE` VÀ THỰC HIỆN 1 SỐ REQUEST Ở ĐOẠN GHI `LOGS` CỦA `MICROSERVICES`, CHÚNG TA CÓ THỂ TRUY CẬP VÀO `http://localhost:3000` CỦA `GRAFANA` ĐỂ XEM `LOGS` CỦA `MICROSERVICES` CÓ DẠNG (name-service, trace-id, span-id) ĐỂ THEO DÕI CÁC REQUEST TRONG HỆ THỐNG.

SAU ĐÓ COPY `TRACE-ID` CỦA REQUEST ĐÓ VÀO `EXPLORE` CHỌN `TEMPO`, PASS `TRACE-ID` VÀO `SEARCH` ĐỂ XEM `TRACES` CỦA REQUEST ĐÓ. CHÚNG TA CÓ THỂ XEM `TRACES` CỦA CÁC REQUEST ĐÓ VỚI CÁC BƯỚC XỬ LÝ CỦA CÁC `MICROSERVICES`.

### 5.4. Tạo Navigation trong `Grafana` khi ấn vào `TraceID` sẽ chuyển sang `Tempo` để xem `Traces` của `Microservices`.
Để tạo `Navigation` trong `Grafana` khi ấn vào `TraceID` trong `Logs` của `Loki` sẽ chuyển sang `Tempo` để xem `Traces` của `Microservices`, chúng ta cần thêm `derivedFields` vào `Loki` trong `datasources` của file cấu hình `grafana-config.yml` như sau:
```yml
...
datasources: # Tạo datasource mới
  ...
  - name: Loki # Tên datasource
    type: loki
    uid: loki
    access: proxy
    orgId: 1
    editable: true
    url: http://gateway:3100 # URL của Loki lấy từ gateway service trong docker-compose.yml
    jsonData:
      httpHeaderName1: "X-Scope-OrgID" # Header name
      derivedFields: # Trường dữ liệu tạo ra
        - datasourceUid: tempo # UID của datasource Tempo
          matcherRegex: "\\[.+,(.+),.+\\]" # Regex để match dữ liệu
          name: TraceID # Tên trường dữ liệu
          url: '$${__value.raw}' # URL để lấy dữ liệu từ datasource
    secureJsonData: # Dữ liệu JSON bảo mật
      httpHeaderValue1: "tenant1"
...
```