# A. Giới thiệu các khái niệm chung về Kubernetes
## 1. Kubernetes là gì?
`Kubernetes` là một hệ thống mã nguồn mở giúp quản lý các container. `Kubernetes` giúp bạn tự động hóa việc triển khai, mở rộng và quản lý các ứng dụng chứa trong các container. Nó là hệ thống quản lý container phổ biến nhất hiện nay và nó là một đám mây trung tính (cloud-neutral) với khả năng chạy trên nhiều hệ thống đám mây công cộng, riêng tư hoặc hệ thống vật lý.

`Kubernetes` cung cấp cho người dùng với 1 `framework` để chạy các hệ thống phân tán một cách ổn định. Nó quan tâm tới việc mở rộng, khả năng chịu lỗi cho ứng dụng và cung cấp các mẫu triển khai ứng dụng. Nó cung cấp với các tính năng như:
- `Service discovery and load balancing`: `Kubernetes` có thể khám phá các dịch vụ và phân phối các yêu cầu đến các dịch vụ đó. **`Có thể thay thế Eureka Server trong Spring Cloud`**.
- `Container & storage orchestration`: `Kubernetes` cho phép bạn tự động chuyển các container đến các máy chủ mới khi cần thiết.
- `Automated rollouts and rollbacks`: `Kubernetes` cho phép bạn thực hiện triển khai mới mà không cần gián đoạn dịch vụ cũng như quay lại phiên bản cũ nếu cần.
- `Self-healing`: `Kubernetes` có khả năng tự động khôi phục các container khi chúng bị lỗi.
- `Secret and configuration management`: `Kubernetes` cho phép bạn quản lý và lưu trữ các thông tin nhạy cảm như `password`, `OAuth tokens` và `SSH keys`.

## 2. Kiến trúc của Kubernetes
`Kubernetes` có kiến trúc `master-slave` với các thành phần chính như sau:
1. `Control Panel/Master Node`: Chịu trách nhiệm quản lý toàn bộ `cluster`. Nó giám sát việc kiểm tra tình trạng của tất cả các `node` trong `cluster`, lưu trữ thông tin của các thành viên liên quan đến các `node` khác nhau, lập kế hoạch cho các `container` được lên lịch cho các `Worker Node` nhất định, giám sát các `container` và `node`, v.v. Vì vậy, khi một `Worker node` bị lỗi, `Master node` sẽ di chuyển khối lượng công việc từ `node` bị lỗi đến `Worker Node` khỏe mạnh khác.
    - `API Server`: Là giao diện chính để tương tác với `K8s cluster`. Nó show ra các API của `k8s`, cho phép người dùng và các thành phần khác giao tiếp với các `cluster`. Tất cả lệnh điều khiển, hoạt động của quản trị viên được gửi tới `API Server` và nó sẽ thực thi và xác thực các yêu cầu đó.
    - `Scheduler`: Có trách nhiệm đặt các `Pod` vào các `node` có sẵn trong `cluster`. Nó sẽ tính đến các yếu tố như `yêu cầu tài nguyên`, `mối quan hệ`, `chống đối quan hệ`, và các ràng buộc khác để đưa ra quyết định thông min xem `node` nào sẽ chứa `Pod`. `Scheduler` liên tục theo dõi các `cluster` đảm bảo các `Pod` được phân phối 1 cách tối ưu.
    - `Controller Manager`: Trình quản lý việc duy trì các `cluster`. Nó xử lý các lỗi `node`, nhân bản các thành phần, đảm bảo đúng số lượng `Pod` chạy và các `controller` khác. Nó luôn giữ hệ thống ở trạng thái mong muốn bằng cách so sánh trạng thái hiện tại với trạng thái mong muốn.
    - `etcd`: Là kho lưu trữ `key-value` phân tán, đóng vai trò là kho lưu trữ dữ liệu chính của `cluster`. Nó lưu trữ các `dữ liệu cấu hình` và `trạng thái mong muốn` của hệ thống, bao gồm thông tin về `Pods`, `Services`, `Replication Controllers`, `Endpoints` và `Nodes`. `API Server` tương tác với `etcd` để đọc và ghi dữ liệu `cluster`.
2. `Worker Node`: Không gì khác ngoài một `máy ảo` (VM) chạy trên đám mây hoặc tại chỗ. Vì vậy, bất kỳ phần cứng nào có khả năng chạy thời gian chạy container đều có thể trở thành `Worker Node`. Các `node` này hiển thị khả năng tính toán, lưu trữ và kết nối mạng cơ bản cho các ứng dụng. Các `Worker Node` thực hiện công việc nặng nhọc cho ứng dụng chạy bên trong `Kubernetes Cluster`. Đồng thời, các `node` này tạo thành một `cluster` - việc phân công khối lượng công việc được thực hiện bởi thành phần `Master Node`, tương tự như cách người quản lý giao nhiệm vụ cho một thành viên trong nhóm. Bằng cách này, chúng sẽ có thể đạt được khả năng chịu lỗi và nhân rộng.
    - `Pod` là đơn vị triển khai nhỏ nhất trong Kubernetes cũng như container là đơn vị triển khai nhỏ nhất trong Docker. Để hiểu một cách dễ hiểu, chúng ta có thể nói rằng `pod` không là gì ngoài những `máy ảo nhẹ trong thế giới ảo`. Mỗi nhóm bao gồm một hoặc nhiều container. Mỗi khi một nhóm hoạt động, nó sẽ nhận được một địa chỉ IP mới với dải IP ảo do giải pháp mạng nhóm chỉ định.
    - `Kubelet`: Là một thành phần chạy trên mỗi `Worker Node` và giao tiếp với các thành phần trong `control plane`. Nó nhận được hướng dẫn từ `control plane`, chẳng hạn như tạo và xóa `Pod` và đảm bảo duy trì trạng thái mong muốn của `Pod` trong `node`. `Kubelet` chịu trách nhiệm cho việc `bắt đầu`, `dừng lại`, `giám sát` các `container` dựa trên thông số kỹ thuật của `Pod`.
    - `Kube-proxy`: Là một proxy mạng chạy trên mỗi `Worker Node` trong `Cluster`, triển khai một phần nội dung của `Kubernetes Service`. `Kube-proxy` duy các `quy tắc` mạng trên các `node`. Các `quy tắc` này cho phép giao tiếp mạng tới `Pod` từ các phiên mạng bên trong hoặc bên ngoài `Cluster`.
    - `Container Runtime`: Chịu trách nhiệm `chạy` và `quản lý` các `container` trên `Worker Node`. Kubernetes hỗ trợ nhiều `container runtime`, trong đó Docker được sử dụng phổ biến nhất. Các `runtime` khác như `containerd` và `rkt` cũng được hỗ trợ. `Container Runtime` lấy `container image`, tạo và quản lý các phiên bản `container` cũng như xử lý các hoạt động trong vòng đời của `container`.

# B. Cài đặt `Kubernetes` trên `Docker Desktop` (Xây dụng Kubernetes cục bộ)
## 1. Settings trong `Docker Desktop`
Để deploy `Kubernetes` trên `Docker Desktop`, xem hướng dẫn tại đây [Deploy on Kubernetes with Docker Desktop](https://docs.docker.com/desktop/kubernetes/)

## 2. Cài đặt `Helm`
`Helm` là một công cụ quản lý gói cho `Kubernetes`. Nó cho phép bạn định nghĩa, cài đặt và quản lý các ứng dụng `Kubernetes`. Để cài đặt `Helm`, xem hướng dẫn tại đây [Installing Helm](https://helm.sh/docs/intro/install/)

Sau khi cài xong, kiểm tra phiên bản `Helm` bằng câu lệnh:
```bash
helm version
```

## 3. Cài `Kubernetes UI` (Dashboard) trên máy cục bộ
### 3.1. Để cài `Kubernetes UI` trên máy cục bộ, trước hết cần phải có `Kubernetes` và cần cài `Helm` trước. Sau đó, tham khảo hướng dẫn tại đây [Kubernetes Dashboard](https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/)

Câu lệnh cài đặt `Kubernetes UI`:
```bash
# Add thư viện Kubernetes Dashboard 
helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/

# Cài đặt Kubernetes Dashboard với namespace kubernetes-dashboard
helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard --create-namespace --namespace kubernetes-dashboard
```
### 3.2. Sau khi cài đặt xong, sử dụng câu lệnh sau để kiểm tra xem `kubernetes-dashboard-kong-proxy` đã được cài đặt thành công chưa:
```bash
# Lấy ra các service trong namespace kubernetes-dashboard
kubectl -n kubernetes-dashboard get svc
```

### 3.3. Để khởi động `Kubernetes UI`, sử dụng câu lệnh sau:
```bash
# Khởi động Kubernetes UI
kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443
```
> Sau khi khởi động thành công, truy cập vào `https://localhost:8443` để xem `Kubernetes UI`. Lưu ý, cần phải giữ phiên làm việc của Terminal để chạy `Kubernetes UI`.

### 3.4. Để đăng nhập vào `Kubernetes UI`, cần phải lấy ra `token` để đăng nhập. Trước hết cần phải tạo một `Service Account` và `Cluster Role Binding` cho `Service Account` đó.
Tham khảo các bước tại [Creating sample user](https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md)

1. Tạo một `Service Account` với tên `admin-user` trong namespace đã tạo là `kubernetes-dashboard`, cấu hình trong file `dashboard-adminuser.yaml`:
    >`dashboard-adminuser.yaml`
    ```yaml
    apiVersion: v1 # Version của API dùng để tạo Service Account
    kind: ServiceAccount # Loại tài khoản 
    metadata: # Thông tin về Service Account
        name: admin-user # Tên Service Account (giống như username)
        namespace: kubernetes-dashboard # Namespace của Service Account (giống như group)
    ```
    Sau đó, sử dụng câu lệnh sau để tạo `Service Account`:
    ```bash
    kubectl apply -f dashboard-adminuser.yaml
    ```

2. Tạo `Cluster Role Binding` để cấp quyền cho `Service Account` vừa tạo, cấu hình trong file `dashboard-adminuser-rolebinding.yaml`:
    >`dashboard-adminuser-rolebinding.yaml`
    ```yaml
    apiVersion: rbac.authorization.k8s.io/v1 # Version của API dùng để tạo Cluster Role Binding
    kind: ClusterRoleBinding # Loại quyền
    metadata: # Thông tin về Cluster Role Binding
        name: admin-user # Tên Cluster Role Binding
    roleRef: # Thông tin về Role
        apiGroup: rbac.authorization.k8s.io # Group của Role
        kind: ClusterRole # Loại Role
        name: cluster-admin # Tên Role, bất kỳ người dùng nào được gán Role này sẽ có quyền quản trị toàn bộ Cluster
    subjects: # Danh sách các đối tượng được cấp quyền
    - kind: ServiceAccount # Loại đối tượng được cấp quyền
        name: admin-user # Tên đối tượng
        namespace: kubernetes-dashboard # Namespace của đối tượng
    ```
    Sau đó, sử dụng câu lệnh sau để tạo `Cluster Role Binding`:
    ```bash
    kubectl apply -f dashboard-adminuser-rolebinding.yaml
    ```

3. Đây là bước tùy chọn. Nếu muốn tạo ra `token` của user `admin-user` để đăng nhập vào `Kubernetes UI` một cách lâu dài, vĩnh viễn thì cần thêm cấu hình sau vào file `secret.yaml`. Còn không thì mỗi lần đăng nhập sẽ phải tạo `token` mới.
    >`secret.yaml`
    ```yaml
    apiVersion: v1 # Version của API dùng để tạo Secret
    kind: Secret # Loại Secret
    metadata: # Thông tin về Secret
        name: admin-user # Tên Secret
        namespace: kubernetes-dashboard # Namespace của Secret
        annotations: # Các chú thích
            kubernetes.io/service-account.name: admin-user # Tên Service Account
    type: kubernetes.io/service-account-token # Loại Secret
    ```
    Sau đó, sử dụng câu lệnh sau để tạo `Secret`:
    ```bash
    kubectl apply -f secret.yaml
    ```
    > Lưu ý: Nếu không tạo `Secret`, mỗi lần đăng nhập vào `Kubernetes UI` sẽ phải tạo `token` mới.

4. Lấy ra `token` của `Service Account` `admin-user` để đăng nhập vào `Kubernetes UI`:
    ```bash
    # Lấy ra token của Service Account admin-user
    kubectl -n kubernetes-dashboard create token admin-user
    ```
    Trong đó `-n` là `namespace` của `Service Account` và `create token` là câu lệnh để tạo `token` cho `Service Account`.

5. Sau khi lấy ra `token`, truy cập vào `Kubernetes UI` và nhập `token` để đăng nhập.

# C. Container Orchestration (Sự điều phối, quản lý các container) sử dụng Kubernetes
> LƯU Ý: CẤU HÌNH FILE `YAML` TRONG `DOCKER COMPOSE` KHÁC VỚI CẤU HÌNH FILE `YAML` TRONG `KUBERNETES`. CẦN CHÚ Ý ĐẾN CÁC THUỘC TÍNH KHÁC NHAU GIỮA 2 LOẠI FILE NÀY.
> LƯU Ý: TrONG FILe `YAML` TRIỂN KHAI `APP` TRÊN `KUBERNETES` CẦN PHẢI CÓ ÍT NHẤT 2 CẤU HÌNH CHÍNH LÀ `Deployment` (Dùng để triển khai ứng dụng) VÀ `Service` (Dùng để kết nối ứng dụng với mạng bên ngoài). NGOÀI RA CÒN CÓ CẤU HÌNH `ConfigMap` (Dùng để lưu trữ cấu hình, các biến môi trường) VÀ `Secret` (Dùng để lưu trữ thông tin nhạy cảm như `password`, `OAuth tokens`, `SSH keys`). VÀ CÁC CẤU HÌNH NÀY NÊN ĐỊNH NGHĨA TRONG CÙNG **1 FILE YAML** THAY VÌ TẠO RA NHIỀU FILE YAML KHÁC NHAU, VÀ TÁCH BIỆT NHAU BỞI KÝ TỰ `---` GIỮA CÁC CẤU HÌNH, NGẦM CHO `KUBERNETES` HIỂU 2 CẤU HÌNH NÀY THỰC RA LÀ THUỘC 2 FILE `YAML` KHÁC NHAU.

## 1. Cấu hình `ConfigMap` trong `Kubernetes` để lưu trữ các biến môi trường cho `Microservices`
`ConfigMap` chỉ khác `Secret` ở chỗ là `ConfigMap` không mã hóa dữ liệu, còn `Secret` thì có. `ConfigMap` được sử dụng để lưu trữ các cấu hình, các biến môi trường cho `Microservices`. Để tạo `ConfigMap`, tạo file `configmap.yml` với nội dung như sau:
>configmap.yml
```yaml
apiVersion: v1 # apiVersion dùng để tạo ConfigMap
kind: ConfigMap # Loại cấu hình (ConfigMap)
metadata: # Thông tin về ConfigMap
  name: bank-configmap # Tên ConfigMap
data: # Dữ liệu của ConfigMap
  SPRING_PROFILES_ACTIVE: prod
  SPRING_CONFIG_IMPORT: "configserver:http://configserver:8071/" # Thuộc tính spring.config.import trong (application.properties) của ứng dụng
  EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: "http://eurekaserver:8070/eureka/" # Thuộc tính eureka.client.serviceUrl.defaultZone trong (application.properties) của ứng dụng
  CONFIGSERVER_APPLICATION_NAME: configserver  # Thuộc tính spring.application.name trong (application.properties) của ứng dụng configserver
  EUREKA_APPLICATION_NAME: eurekaserver # Thuộc tính spring.application.name trong (application.properties) của ứng dụng eurekaserver
  ACCOUNTS_APPLICATION_NAME: accounts # Thuộc tính spring.application.name trong (application.properties) của ứng dụng accounts
  LOANS_APPLICATION_NAME: loans # Thuộc tính spring.application.name trong (application.properties) của ứng dụng loans
  CARDS_APPLICATION_NAME: cards # Thuộc tính spring.application.name trong (application.properties) của ứng dụng cards
  GATEWAY_APPLICATION_NAME: gatewayserver # Thuộc tính spring.application.name trong (application.properties) của ứng dụng gatewayserver
  KEYCLOAK_ADMIN: admin # Thuộc tính KEYCLOAK_ADMIN khi chạy docker run
  KEYCLOAK_ADMIN_PASSWORD: admin # Thuộc tính KEYCLOAK_ADMIN_PASSWORD khi chạy docker run
  SPRING_SECURITY_OAUTH2_RESOURCESERVER_JWT_JWK-SET-URI: "http://keycloak:7080/realms/master/protocol/openid-connect/certs" # Thuộc tính spring.security.oauth2.resourceserver.jwt.jwk-set-uri trong (application.properties) của ứng dụng
```
Để sử dụng các biến môi trường trong `ConfigMap`, cần thêm cấu hình sau vào file `.yml`:
```yaml
...
    template:
     metadata:
      ...
     spec:
      containers:
       - name: ...
         args: ... # DÙNG ĐỂ CHẠY CÁC LỆNH TRONG CONTAINER
         env: # SỬ DỤNG BIẾN MÔI TRƯỜNG
         - name: ... # TÊN BIẾN MÔI TRƯỜNG Ở BÊN TRONG APP CONTAINER
         valueFrom: # LẤY GIÁ TRỊ TỪ
          configMapKeyRef: # THAM CHIẾU ĐẾN CONFIGMAP
           name: bank-configmap # TÊN CỦA CONFIGMAP 
           key: SPRING_PROFILES_ACTIVE # TÊN CỦA BIẾN MÔI TRƯỜNG TRONG CONFIGMAP (KEY)
...
```
        
## 2. Triênt khai `Keycloak` trên `Kubernetes`
Trước tiên cần tạo `image` của `Keycloak` và `push` lên `Docker Hub` hoặc `GitHub Container Registry`. Sau đó, triển khai `Keycloak` trên `Kubernetes` bằng cách sử dụng `Deployment` và `Service`.
>keycloak.yml
```yaml
apiVersion: apps/v1 # apiVersion dùng để deploy 1 ứng dụng
kind: Deployment # Loại cấu hình (Deployment) - dùng để deploy 1 ứng dụng
metadata:
  name: keycloak # Tên Deployment
  labels:
    app: keycloak # Gán nhãn cho ứng dụng được deploy (keycloak)
spec:
  selector:
    matchLabels:
      app: keycloak # Chọn Pod có nhãn app=keycloak để quản lý (trùng với metadata.labels.app)
  template:
    metadata:
      labels:
        app: keycloak # Nhãn của Pod (phải trùng với selector.matchLabels.app và metadata.labels.app ở trên)
    spec:
      containers:
        - name: keycloak # Tên container (nên đặt tên giống với metadata.labels.app ở trên)
          image: quay.io/keycloak/keycloak:25.0.2
          args: ["start-dev"]
          env:
            - name: KEYCLOAK_ADMIN
              valueFrom:
                configMapKeyRef:
                  name: bank-configmap
                  key: KEYCLOAK_ADMIN
            - name: KEYCLOAK_ADMIN_PASSWORD
              valueFrom:
                configMapKeyRef:
                  name: bank-configmap
                  key: KEYCLOAK_ADMIN_PASSWORD
          ports:
            - name: http # Đặt tên cho cổng để dễ nhận biết cổng này thuộc về dịch vụ gì
              containerPort: 8080 # Cổng 8080
---
apiVersion: v1 # apiVersion dùng để triển khai 1 dịch vụ
kind: Service # Loại cấu hình (Service)
metadata:
  name: keycloak # Tên Service (tên này sẽ như là 1 hostname để gọi đến các Pod, trong `Docker Compose` thì sẽ là tên của service)
spec:
  selector:
    app: keycloak # Chọn Pod có nhãn app=keycloak để quản lý (trùng với metadata.labels.app cấu hình `Deployment`)
  type: LoadBalancer # Loại Service [LoadBalancer (Map cổng ra bên ngoài), NodePort (Map cổng ra bên ngoài), ClusterIP (Chỉ sử dụng trong Cluster)]
  ports:
    - name: http # Đặt tên cho cổng để dễ nhận biết cổng này thuộc về dịch vụ gì
      port: 7080 # Cổng 7080 sẽ map ra bên ngoài
      targetPort: 8080 # Đích đến của dịch vụ (cổng 8080 của bên trong Pod)

```
Sau khi định nghĩa xong file `keycloak.yml`, sử dụng câu lệnh sau để triển khai `Keycloak` lên `Kubernetes`:
```bash
kubectl apply -f keycloak.yml
```

## 3. Triển khai `Spring Cloud Config Server` trên `Kubernetes`
Trước tiên cần tạo `image` của `Spring Cloud Config Server` và `push` lên `Docker Hub` hoặc `GitHub Container Registry`. Sau đó, triển khai `Spring Cloud Config Server` trên `Kubernetes` bằng cách sử dụng `Deployment` và `Service`.
>configserver.yml
```yaml
apiVersion: apps/v1 # apiVersion dùng để deploy 1 ứng dụng
kind: Deployment # Loại cấu hình (Deployment) - dùng để deploy 1 ứng dụng
metadata: # Thông tin về Deployment
  name: configserver-deployment # Tên Deployment
  labels:
    app: configserver # Gán nhãn cho ứng dụng được deploy (configserver)
spec: # Thông tin về cấu hình của Deployment
  replicas: 1 # Số lượng Pod được tạo ra từ Deployment
  selector:
    matchLabels: # Chọn Pod dựa trên nhãn
      app: configserver # Chọn Pod có nhãn app=configserver để quản lý (trùng với metadata.labels.app)
  template: # Template của Pod 
    metadata: # Thông tin về Pod
      labels:
        app: configserver # Nhãn của Pod (phải trùng với selector.matchLabels.app và metadata.labels.app ở trên)
    spec: # Thông tin về cấu hình của Pod
      containers: # Thông tin về container (Lưu ý nên chỉ có 1 container trong 1 Pod, nếu cần nhiều container thì tạo nhiều Pod, hoặc nếu có 1 container phụ thuộc vào container chính thì sử dụng sidecar container)
      - name: configserver # Tên container (nên đặt tên giống với metadata.labels.app ở trên)
        image: dannguyenmessi/configserver:v1 # Image của container (không có prefix thì sẽ lấy image từ Local, nếu muốn lấy image từ Docker Hub thì phải thêm prefix docker.io/ trước tên image)
        ports: # Cổng mà container sẽ sử dụng ở bên trong Pod
        - containerPort: 8071 # Cổng 8071
--- # Dấu --- để phân biệt giữa các cấu hình Deployment và Service
apiVersion: v1 # apiVersion dùng để triển khai 1 dịch vụ
kind: Service # Loại cấu hình (Service)
metadata: # Thông tin về Service
  name: configserver # Tên Service (tên này sẽ như là 1 hostname để gọi đến các Pod, trong `Docker Compose` thì sẽ là tên của service)
spec: # Thông tin về cấu hình của Service
  selector: # Chọn Pod dựa trên nhãn
    app: configserver # Chọn Pod có nhãn app=configserver để quản lý (trùng với metadata.labels.app cấu hình `Deployment`)
  type: LoadBalancer # Loại Service [LoadBalancer (Map cổng ra bên ngoài), NodePort (Map cổng ra bên ngoài), ClusterIP (Chỉ sử dụng trong Cluster)]
  ports: # Cổng mà Service sẽ sử dụng ở bên ngoài
  - protocol: TCP # Giao thức TCP
    port: 8071 # Cổng 8071 sẽ map ra bên ngoài
    targetPort: 8071 # Đích đến của dịch vụ (cổng 8071 của bên trong Pod)
```
Sau khi định nghĩa xong file `configserver.yml`, sử dụng câu lệnh sau để triển khai `Spring Cloud Config Server` lên `Kubernetes`:
```bash
kubectl apply -f configserver.yml
```

Tương tự với các `Microservices` khác, cần phải triển khai `Eureka Server`, `Gateway Server`, `Accounts Service`, `Loans Service`, `Cards Service` lên `Kubernetes` bằng cách sử dụng `Deployment` và `Service`.

NHƯ VẬY, NẾU TẠO NHIỀU `REPLICAS` CHO 1 `DEPLOYMENT`, KHI CHẠY ỨNG DỤNG, CÁC `POD` SẼ ĐƯỢC PHÂN PHỐI ĐỀU TRÊN CÁC `NODE` TRONG `CLUSTER`. NẾU CÓ 1 `POD` BỊ LỖI HOẶC BỊ SHUTDOWN, `KUBERNETES` SẼ TỰ ĐỘNG KHÔI PHỤC `POD` ĐÓ MÀ KHÔNG CẦN PHẢI CAN THIỆP. VÀ SỐ LƯỢNG `POD` VẪN ĐƯỢC PHỤC HỒI NHƯ BAN ĐẦU.

# D. Các phân loại `Service` trong `Kubernetes`
Chúng ta có thể nhận ra rằng có 3 loại `Service` trong `Kubernetes` ở trong file `yml` của cấu hình `Service`:
```yaml
...
  type: LoadBalancer # Loại Service [LoadBalancer (Map cổng ra bên ngoài), NodePort (Map cổng ra bên ngoài), ClusterIP (Chỉ sử dụng trong Cluster)]
...
```
Có 3 loại `Service` trong `Kubernetes`:
1. `ClusterIP` Service: Dùng để kết nối các `Pod` trong `Cluster`. `ClusterIP` Service chỉ có thể truy cập từ bên trong `Cluster` và không thể truy cập từ bên ngoài `Cluster`. `ClusterIP` Service được sử dụng để kết nối các `Pod` với nhau trong `Cluster`.
  VD: 
  ```yaml
  ...
  spec:
    selector:
      app: configserver
    type: ClusterIP
    ports:
      - protocol: TCP
        port: 80
        targetPort: 8071
  ...
  ```
  > Chỉ có thể truy cập `configserver` từ bên trong `Cluster` thông qua cổng `80`, với `targetPort` là cổng `8071` của `Pod`. Và không thể truy cập từ bên ngoài `Cluster`.

2. `NodePort` Service: Dùng để kết nối các `Pod` trong `Cluster` và cũng có thể truy cập từ bên ngoài `Cluster`. `NodePort` sử dụng giá trị từ `30000` đến `32767` để mở cổng truy cập từ bên ngoài `Cluster`. `NodePort` Service được sử dụng để kết nối các `Pod` với nhau trong `Cluster` và cũng có thể truy cập từ bên ngoài `Cluster`.
  VD:
  ```yaml
  ...
  spec:
    selector:
      app: configserver
    type: NodePort
    ports:
      - protocol: TCP
        port: 80
        targetPort: 8071
        nodePort: 30001
  ...
  ```
  > Có thể truy cập `configserver` từ bên trong `Cluster` thông qua `<NodeIP>:30001`, với `targetPort` là cổng `8071` của `Pod`. Và cũng có thể truy cập từ bên ngoài `Cluster`.

3. `LoadBalancer` Service: Dùng để kết nối các `Pod` trong `Cluster` và cũng có thể truy cập từ bên ngoài `Cluster`. `LoadBalancer` Service được sử dụng để kết nối các `Pod` với nhau trong `Cluster` và cũng có thể truy cập từ bên ngoài `Cluster`. Nó giống với `NodePort` Service nhưng có thêm `LoadBalancer` để phân phối tải.
  VD:
  ```yaml
  ...
  spec:
    selector:
      app: configserver
    type: LoadBalancer
    ports:
      - protocol: TCP
        port: 80
        targetPort: 8071
  ...
  ```
  > Có thể truy cập `configserver` từ bên trong `Cluster` thông qua cổng `80`, với `targetPort` là cổng `8071` của `Pod`. Và cũng có thể truy cập từ bên ngoài `Cluster`.

# E. Helm
## 1. Giới thiệu về `Helm`
`Helm` hoạt động như một `package manager` cho `Kubernetes`. Giống như `package manager` là một tập hợp các công cụ phần mềm, tự động các tiến trình như `cài đặt`, `nâng cấp phiên bản quản lý`, `xóa các ứng dụng trên máy tính` một cách nhất quán. `Helm` cũng tự động hóa việc cài đặt, khôi phục, nâng cấp nhiều `K8s manifest` với một lệnh duy nhất.

Các lợi ích của `Helm`:
- `Helm` hỗ trợ đóng gói các file `YAML` thành một `chart` duy nhất: Với sự giúp đỡ của `Helm` chúng ta có thể đóng gói các file `yaml manifest` thành một ứng dụng bên trong một `chart` duy nhất. Điều tương tự có thể được phân phối lên các `public` hoặc `private repositories` để chia sẻ với cộng đồng hoặc tự sử dụng.
- `Helm` hỗ trợ viễ cài đặt dễ dàng hơn: Với sự giúp đỡ từ `Helm` chúng ta có thể `thiết lập/nâng cấp/khôi phục/xóa bỏ` toàn bộ các ứng dụng bên trong K8s chỉ với `1 lệnh` duy nhất (Không cần phải chạy thủ công các lệnh `kubectl apply` cho từng tệp `manifest`).
- `Helm` hỗ trợ xuất xưởng và quản lý phiên bản: `Helm` tự động duy trì lịch sử của các `manifest` đã được cài đặt. Do đó, việc khôi phục toàn bộ `K8s Cluster` về trạng thái hoạt động trước đó chỉ cần là 1 lệnh duy nhất.


# Các câu lệnh cơ bản trong Kubernetes
1. `kubectl config get-contexts`: Hiển thị danh sách các `context` trong `kubeconfig`. 
2. `kubectl config use-context <name-context>`: Chuyển đổi giữa các `context` trong `kubeconfig`.
3. `kubectl get nodes`: Hiển thị danh sách các `node` trong `cluster`.
4. `kubectl get deployments`: Hiển thị danh sách các `deployment` trong `cluster`.
5. `kubectl get pods`: Hiển thị danh sách các `pod` trong `cluster`.
6. `kubectl get services`: Hiển thị danh sách các `service` trong `cluster`.
7. `kubectl get namespaces`: Hiển thị danh sách các `namespace` trong `cluster`.
8. `kubectl get replicaset`: Hiển thị danh sách các `replicaset`(bộ nhân bản) trong `cluster`.
9. `kubectl apply -f <file.yaml>`: Áp dụng, chạy cấu hình từ file `yaml` vào `cluster`.
10. `kubectl delete -n default --now <tên cấu hình> <name> --cascade=background`: Xóa `các dịch vụ tên cấu hình như deployment, configmap,...`  có tên `<name>` trong `namespace` mặc định `default`.
11. `kubectl get events --sort-by=.metadata.creationTimestamp`: Hiển thị các sự kiện trong `cluster` được sắp xếp theo thời gian tạo.
12. `kubectl scale deployment <tên deployment> --replicas=<số lượng replicas>`: Scale `deployment` có tên `<tên deployment>` lên với số lượng `replicas` là `<số lượng replicas>`. Cách này giúp tăng hoặc giảm số lượng `replicas` của `deployment` một cách nhanh chóng. Thay vì phải sửa file `yaml` và `apply` lại, ta có thể sử dụng câu lệnh này để thay đổi số lượng `replicas` của `deployment`.
13. `kubectl exec -it <tên pod> -- /bin/bash`: Truy cập vào `container` của `pod` có tên `<tên pod>` và thực thi lệnh `/bin/bash`. Cách này giúp truy cập vào `container` của `pod` một cách nhanh chóng và dễ dàng.
14. `kubectl logs <tên pod>`: Hiển thị `logs` của `pod` có tên `<tên pod>`. Cách này giúp hiển thị `logs` của `pod` một cách nhanh chóng và dễ dàng.
15. `kubectl describe pod <tên pod>`: Hiển thị thông tin chi tiết của `pod` có tên `<tên pod>`. Cách này giúp hiển thị thông tin chi tiết của `pod` một cách nhanh chóng và dễ dàng.
16. `kubectl set image deployment <tên deployment> <tên container>=<image mới> --record`: Thay đổi `image` của `container` trong `deployment` có tên `<tên deployment>` thành `image` mới là `<image mới>`. Cách này giúp thay đổi `image` của `container` trong `deployment` một cách nhanh chóng và dễ dàng.
17. `kubectl get configmaps`: Hiển thị danh sách các `configmaps` trong `cluster`.
18. `kubectl get secrets`: Hiển thị danh sách các `secrets` trong `cluster`.
19. `kubectl rollout history deployment <tên deployment>`: Hiển thị lịch sử `rollout` của `deployment` có tên `<tên deployment>`. Cách này giúp hiển thị lịch sử `rollout` của `deployment` một cách nhanh chóng và dễ dàng.
20. `kubectl rollout undo deployment <tên deployment> --to-revision=<số revision>`: Rollback `deployment` có tên `<tên deployment>` về phiên bản `revision` có số `<số revision>`. Cách này giúp rollback `deployment` về phiên bản trước đó một cách nhanh chóng và dễ dàng.